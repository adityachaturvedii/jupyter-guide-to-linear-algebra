
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Approximating Eigenvalues &#8212; Jupyter Guide to Linear Algebra</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Approximating_Eigenvalues';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Applications of Eigenvalues and Eigenvectors" href="Applications_EV.html" />
    <link rel="prev" title="Diagonalization" href="Diagonalization.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/reflection_logo.png" class="logo__image only-light" alt="Jupyter Guide to Linear Algebra - Home"/>
    <script>document.write(`<img src="_static/reflection_logo.png" class="logo__image only-dark" alt="Jupyter Guide to Linear Algebra - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to the Jupyter Guide to Linear Algebra
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="Jupyter_Introduction.html">Introduction to Jupyter</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="Python_Introduction.html">Introduction to Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="Numpy_Introduction.html">Introduction to NumPy and Matplotlib</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="Linear_Systems.html">Linear Systems</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="Gaussian_Elimination.html">Gaussian Elimination</a></li>
<li class="toctree-l2"><a class="reference internal" href="Matrix_Algebra.html">Matrix Algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="Solving_Systems.html">Solving Systems using Elimination</a></li>
<li class="toctree-l2"><a class="reference internal" href="Inverse_Matrices.html">Inverse Matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="LU_Factorization.html">LU Factorization</a></li>
<li class="toctree-l2"><a class="reference internal" href="Applications.html">Applications of Linear Systems and Matrix Algebra</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="Vector_Spaces.html">Vector Spaces</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="General_Linear_Systems.html">General Linear Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="Linear_Combinations.html">Linear Combinations</a></li>
<li class="toctree-l2"><a class="reference internal" href="Linear_Independence.html">Linear Independence</a></li>
<li class="toctree-l2"><a class="reference internal" href="Bases.html">Bases</a></li>
<li class="toctree-l2"><a class="reference internal" href="Vector_Space_Examples.html">Vector Space Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="Applications_VS.html">Applications of Vector Spaces</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="Linear_Transformations.html">Linear Transformations</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="Matrix_Representations.html">Matrix Representations</a></li>
<li class="toctree-l2"><a class="reference internal" href="Planar_Transformations.html">Transformations in a Plane</a></li>
<li class="toctree-l2"><a class="reference internal" href="Applications_LT.html">Applications of Linear Transformations</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="Inner_Products.html">Inner Products</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="Orthogonalization.html">Orthogonalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="QR_Factorization.html">QR Factorization</a></li>
<li class="toctree-l2"><a class="reference internal" href="Orthogonal_Subspaces.html">Orthogonal Subspaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="Least_Squares_Solutions.html">Least Squares Solutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="Projections.html">Projections</a></li>
<li class="toctree-l2"><a class="reference internal" href="Applications_IP.html">Applications of Inner Products</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="Eigenvalues.html">Eigenvalues</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Diagonalization.html">Diagonalization</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Approximating Eigenvalues</a></li>
<li class="toctree-l2"><a class="reference internal" href="Applications_EV.html">Applications of Eigenvalues and Eigenvectors</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="Solutions.html">Solutions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="Introduction_Solutions.html">Introduction to Jupyter</a></li>
<li class="toctree-l2"><a class="reference internal" href="Linear_Systems_Solutions.html">Linear Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="Vector_Spaces_Solutions.html">Vector Spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="Linear_Transformations_Solutions.html">Linear Transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="Inner_Products_Solutions.html">Inner Products</a></li>
<li class="toctree-l2"><a class="reference internal" href="Eigenvalues_Solutions.html">Eigenvalues</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/Approximating_Eigenvalues.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Approximating Eigenvalues</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#power-method">Power method</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inverse-power-method">Inverse power method</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shifted-inverse-power-method">Shifted inverse power method</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="approximating-eigenvalues">
<h1>Approximating Eigenvalues<a class="headerlink" href="#approximating-eigenvalues" title="Link to this heading">#</a></h1>
<p>In this section we look at some methods that can be used to approximate the eigenvalues of a matrix <span class="math notranslate nohighlight">\(A\)</span>.  Although it is possible to find the exact eigenvalues for small matrices, the approach is impractical for larger matrices.</p>
<p>Most introductory textbooks demonstrate a direct way to compute eigenvalues of an <span class="math notranslate nohighlight">\(n\times n\)</span> matrix <span class="math notranslate nohighlight">\(A\)</span> by computing roots of an associated <span class="math notranslate nohighlight">\(n\)</span>th degree polynomial, known as the <em>characteristic polynomial</em>.  For example, suppose <span class="math notranslate nohighlight">\(A\)</span> is a <span class="math notranslate nohighlight">\(2\times 2\)</span> matrix.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
A = \left[ \begin{array}{rr} a &amp; b  \\ c &amp; d \end{array}\right]
\end{equation}
\end{split}\]</div>
<p>The eigenvalues of <span class="math notranslate nohighlight">\(A\)</span> are solutions to the quadratic equation <span class="math notranslate nohighlight">\(\lambda^2 - (a+d)\lambda + ad-bc = 0\)</span>, which can be written explicitly in terms of <span class="math notranslate nohighlight">\(a\)</span>, <span class="math notranslate nohighlight">\(b\)</span>, <span class="math notranslate nohighlight">\(c\)</span>, and <span class="math notranslate nohighlight">\(d\)</span> using the quadratic formula.  The challenges with larger matrices are that the polynomial is more difficult to construct, and the roots cannot be easily found with a formula.</p>
<p>The algorithms we describe in this section are iterative methods.  They generate a sequence of vectors <span class="math notranslate nohighlight">\(\{X^{(1)}, X^{(2)}, X^{(3)}, ... \}\)</span> that approach a true eigenvector of the matrix under consideration.  An approximation of the corresponding eigenvalue can then be computed by multiplying the approximate eigenvector by <span class="math notranslate nohighlight">\(A\)</span>.</p>
<section id="power-method">
<h2>Power method<a class="headerlink" href="#power-method" title="Link to this heading">#</a></h2>
<p>The first algorithm we introduce for approximating eigenvalues is known as the <strong>Power Method</strong>.  This method generates a sequence of vectors by repeated matrix multiplication.  Under suitable conditions, the sequence of vectors approaches the eigenvector associated with the eigenvalue that is largest in absolute value.</p>
<p>For the simplest explanation, suppose that <span class="math notranslate nohighlight">\(A\)</span> is an <span class="math notranslate nohighlight">\(n\times n\)</span> diagonalizable matrix with eigenvectors <span class="math notranslate nohighlight">\(\{V_1, V_2, ... V_n\}\)</span>, and that <span class="math notranslate nohighlight">\(\lambda_1\)</span> is the eigenvalue of <span class="math notranslate nohighlight">\(A\)</span> that is largest in absolute value.  To begin the Power Method, we choose any nonzero vector and label it <span class="math notranslate nohighlight">\(X^{(0)}\)</span>.  We can express <span class="math notranslate nohighlight">\(X^{(0)}\)</span>  as a linear combination of the eigenvectors since they form a basis for <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>.</p>
<div class="math notranslate nohighlight">
\[
\begin{equation}
X^{(0)} = c_1V_1 + c_2V_2 + ... c_nV_n
\end{equation}
\]</div>
<p>We now form a sequence of vectors <span class="math notranslate nohighlight">\(X^{(1)}\)</span>, <span class="math notranslate nohighlight">\(X^{(2)}\)</span>, <span class="math notranslate nohighlight">\(X^{(3)}\)</span>, …, by setting <span class="math notranslate nohighlight">\(X^{(m)}= AX^{(m-1)}\)</span>.  Each of these vectors is also easly expressed in terms of the eigenvectors.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{eqnarray*}
X^{(1)} = AX^{(0)} &amp; = &amp; c_1AV_1 + c_2AV_2 + ... c_nAV_n \\
                   &amp; = &amp; c_1\lambda_1V_1 + c_2\lambda_2V_2 + ... c_n\lambda_nV_n \\
X^{(2)} = AX^{(1)} &amp; = &amp; c_1\lambda_1AV_1 + c_2\lambda_2AV_2 + ... c_n\lambda_nAV_n \\
                   &amp; = &amp; c_1\lambda_1^2V_1 + c_2\lambda_2^2V_2 + ... c_n\lambda_n^2V_n \\
                   &amp; \vdots &amp; \\
X^{(m)} = AX^{(m-1)} &amp; = &amp; c_1\lambda_1^{m-1}AV_1 + c_2\lambda_2^{m-1}AV_2 + ... c_n\lambda_n^{m-1}AV_n \\
                   &amp; = &amp; c_1\lambda_1^mV_1 + c_2\lambda_2^mV_2 + ... c_n\lambda_n^mV_n 
\end{eqnarray*}
\end{split}\]</div>
<p>In the expression for <span class="math notranslate nohighlight">\(X^{(m)}\)</span>, we can then factor out <span class="math notranslate nohighlight">\(\lambda_1^m\)</span> to understand what happens as <span class="math notranslate nohighlight">\(m\)</span> gets large.</p>
<div class="math notranslate nohighlight">
\[
\begin{equation}
X^{(m)} =  \lambda_1^m\left(c_1V_1 + c_2\left(\frac{\lambda_2}{\lambda_1}\right)^mV_2 + ... c_n\left(\frac{\lambda_n}{\lambda_1}\right)^mV_n\right) 
\end{equation}
\]</div>
<p>If <span class="math notranslate nohighlight">\(|\lambda_1| &gt; |\lambda_i|\)</span> for all <span class="math notranslate nohighlight">\(i\neq 1\)</span>, then <span class="math notranslate nohighlight">\(|\lambda_i/\lambda_1|&lt; 1\)</span> and <span class="math notranslate nohighlight">\((\lambda_i/\lambda_1)^m\)</span> will approach zero as <span class="math notranslate nohighlight">\(m\)</span> gets large.  This means that if we repeatedly multiply a vector by the matrix <span class="math notranslate nohighlight">\(A\)</span>, eventually we will get a vector that is very nearly in the direction of the eigenvector that corresponds to the <span class="math notranslate nohighlight">\(\lambda_1\)</span>.</p>
<p>Let’s demonstrate the calculation on the matrix shown here before we discuss the method further.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
A = \left[ \begin{array}{rrrr} -2 &amp; 6 &amp; 2 &amp; -8 \\ -6 &amp; 0 &amp; 12 &amp; 12 \\ -6 &amp; 0 &amp; 12 &amp; 12 \\ -10 &amp; 3 &amp; 7 &amp; 14 \end{array}\right]
\end{equation}
\end{split}\]</div>
<p>As a matter of practicality, it is common to scale the vectors in the sequence to unit length as the Power Method is applied.  If the vectors in the sequence are not scaled, their magnitudes will grow if <span class="math notranslate nohighlight">\(\lambda_1&gt;1\)</span> or decay if <span class="math notranslate nohighlight">\(\lambda_1&lt;1\)</span>.    Since all components of the vectors get divided by the same factor when the vector is scaled, this step doesn’t change the ultimate behavior of the sequence.  The scaled sequence of vectors still approaches the direction of the eigenvector.</p>
<p>We choose an arbitrary <span class="math notranslate nohighlight">\(X^{(0)}\)</span> and calculate <span class="math notranslate nohighlight">\(X^{(20)}\)</span> using the following rule.</p>
<div class="math notranslate nohighlight">
\[
\begin{equation}
X^{(m)}=\frac{AX^{(m-1)}}{||AX^{(m-1)}||}
\end{equation}
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">laguide</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">lag</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">8</span><span class="p">],[</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">],[</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">],[</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">14</span><span class="p">]])</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">]])</span>

<span class="n">m</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">while</span> <span class="p">(</span><span class="n">m</span> <span class="o">&lt;</span> <span class="mi">20</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">A</span><span class="nd">@X</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">/</span><span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">m</span> <span class="o">+</span> <span class="mi">1</span>
    
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 1.57523994e-12]
 [-5.77350269e-01]
 [-5.77350269e-01]
 [-5.77350269e-01]]
</pre></div>
</div>
</div>
</div>
<p>Now if <span class="math notranslate nohighlight">\(X\)</span> is the eigenvector of <span class="math notranslate nohighlight">\(A\)</span> with unit magnitude, then <span class="math notranslate nohighlight">\(|AX| = |\lambda_1X| = |\lambda_1|\)</span>.  We can therefore approximate <span class="math notranslate nohighlight">\(|\lambda_1|\)</span> with <span class="math notranslate nohighlight">\(|AX|\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">A</span><span class="nd">@X</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>24.000000000020005
</pre></div>
</div>
</div>
</div>
<p>It appears that 24 is an estimate for <span class="math notranslate nohighlight">\(\lambda_1\)</span>.   To determine if our calculation is correct, we can compare <span class="math notranslate nohighlight">\(AX\)</span> with <span class="math notranslate nohighlight">\(\lambda_1X\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="nd">@X</span> <span class="o">-</span> <span class="mi">24</span><span class="o">*</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[-4.09561274e-11]
 [-9.45021839e-12]
 [-9.45021839e-12]
 [-1.57509561e-11]]
</pre></div>
</div>
</div>
</div>
<p>Indeed the difference <span class="math notranslate nohighlight">\(AX-24X\)</span> is small.  Note that in this case, we can even do the calculation with integer multiplication.  Notice that <span class="math notranslate nohighlight">\(X\)</span> has 0 in the first entry and the other entries are equal.  If we set these entries to 1, the result is easy to calculate even without the aid of the computer.  (<em>Remember that we can change the magnitude of an eigenvector and it is still an eigenvector.</em>)</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
AX = \left[ \begin{array}{rrrr} -2 &amp; 6 &amp; 2 &amp; -8 \\ -6 &amp; 0 &amp; 12 &amp; 12 \\ -6 &amp; 0 &amp; 12 &amp; 12 \\ -10 &amp; 3 &amp; 7 &amp; 14 \end{array}\right]
\left[ \begin{array}{r} 0 \\ 1\\ 1 \\ 1 \end{array}\right] =
\left[ \begin{array}{r} 0 \\ 24\\ 24 \\ 24 \end{array}\right] = 24X
\end{equation}
\end{split}\]</div>
<p>In practice, we do not know how many iterations we need to perform in order to get a good approximation of the eigenvector.  Instead we should specify a condition upon which we will be satisfied with the approximation and terminate the iteration.  For example, since <span class="math notranslate nohighlight">\(||AX^{(m)}||\approx \lambda_1\)</span> and <span class="math notranslate nohighlight">\(AX^{(m)}\approx \lambda_1X^{(m)}\)</span> we might require that <span class="math notranslate nohighlight">\(AX^{(m)} - ||AX^{(m)}||X^{(m)} &lt; \epsilon\)</span> for some small number <span class="math notranslate nohighlight">\(\epsilon\)</span> known as a tolerance.  This condition ensures that <span class="math notranslate nohighlight">\(X^{(m)}\)</span> functions roughly like an eigenvector.  It is also best to include in the code a limit on the number of iterations that will be carried out.  This ensures that the computation will eventually end, even if a satisfactory result has not yet been achieved.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">]])</span>

<span class="n">m</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">tolerance</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">MAX_ITERATIONS</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1">## Compute difference in stopping condition</span>
<span class="c1">## Assign Y = AX to avoid computing AX multiple times</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">A</span><span class="nd">@X</span>
<span class="n">difference</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span><span class="o">*</span><span class="n">X</span>

<span class="k">while</span> <span class="p">(</span><span class="n">m</span> <span class="o">&lt;</span> <span class="n">MAX_ITERATIONS</span> <span class="ow">and</span> <span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">difference</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">tolerance</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">Y</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">/</span><span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="c1">## Compute difference in stopping condition</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">A</span><span class="nd">@X</span>
    <span class="n">difference</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span><span class="o">*</span><span class="n">X</span>
    
    <span class="n">m</span> <span class="o">=</span> <span class="n">m</span> <span class="o">+</span> <span class="mi">1</span>
    
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Eigenvector is approximately:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Magnitude of the eigenvalue is approximately:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">Y</span><span class="p">),</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Magnitude of the difference is:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">difference</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Eigenvector is approximately:
[[ 1.65181395e-06]
 [-5.77350269e-01]
 [-5.77350269e-01]
 [-5.77350269e-01]] 

Magnitude of the eigenvalue is approximately:
24.000020980823063 

Magnitude of the difference is:
4.328470441185797e-05
</pre></div>
</div>
</div>
</div>
<p>A more common condition to require is that <span class="math notranslate nohighlight">\(||X^{(m)} - X^{(m-1})|| &lt; \epsilon\)</span> for a given tolerance <span class="math notranslate nohighlight">\(\epsilon\)</span>.  This condition merely requires that the vectors in the sequence get close to one another, not that they are actually approximate an eigenvector.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">]])</span>

<span class="n">m</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">tolerance</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">MAX_ITERATIONS</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">difference</span> <span class="o">=</span> <span class="n">X</span>

<span class="k">while</span> <span class="p">(</span><span class="n">m</span> <span class="o">&lt;</span> <span class="n">MAX_ITERATIONS</span> <span class="ow">and</span> <span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">difference</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">tolerance</span><span class="p">):</span>
    <span class="n">X_previous</span> <span class="o">=</span> <span class="n">X</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">A</span><span class="nd">@X</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">/</span><span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="c1">## Compute difference in stopping condition</span>
    <span class="n">difference</span> <span class="o">=</span> <span class="n">X</span> <span class="o">-</span> <span class="n">X_previous</span>
    
    <span class="n">m</span> <span class="o">=</span> <span class="n">m</span> <span class="o">+</span> <span class="mi">1</span>
    
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Eigenvector is approximately:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Magnitude of the eigenvalue is approximately:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">Y</span><span class="p">),</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Magnitude of the difference is:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">difference</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Eigenvector is approximately:
[[ 2.64294012e-05]
 [-5.77350269e-01]
 [-5.77350269e-01]
 [-5.77350269e-01]] 

Magnitude of the eigenvalue is approximately:
24.000020980823063 

Magnitude of the difference is:
8.434774776931515e-05
</pre></div>
</div>
</div>
</div>
<p>While the Power Method is easy to understand and apply, it does have disadvantages.  The most apparent disadvantage is that the method only applies to the largest eigenvalue.  This is not a huge detriment since applications often only require an approximation of the largest eigenvalue.  Also, as we will demonstrate below, it is possible to easily modify the method to approximate the other eigenvalues.  A more significant disadvantage is that the rate at which the sequence converges can be slow in some circumstances.  For example, we can see that if <span class="math notranslate nohighlight">\(|\lambda_1|\)</span> is close to <span class="math notranslate nohighlight">\(|\lambda_2|\)</span>, then <span class="math notranslate nohighlight">\(|\lambda_1/\lambda_2|^m\)</span> approaches zero more slowly as <span class="math notranslate nohighlight">\(m\)</span> gets large.  The Power Method may fail to converge at all if <span class="math notranslate nohighlight">\(|\lambda_1| = |\lambda_2|\)</span>, which occurs if <span class="math notranslate nohighlight">\(\lambda_1 = -\lambda_2\)</span>, or if <span class="math notranslate nohighlight">\(\lambda_1\)</span> and <span class="math notranslate nohighlight">\(\lambda_2\)</span> are a complex conjugate pair.  Additionally, the method may perform poorly if the <span class="math notranslate nohighlight">\(V_1\)</span> component of <span class="math notranslate nohighlight">\(X^{(0)}\)</span> is too small.</p>
</section>
<section id="inverse-power-method">
<h2>Inverse power method<a class="headerlink" href="#inverse-power-method" title="Link to this heading">#</a></h2>
<p>The <strong>Inverse Power Method</strong> is a modified version of the Power Method that allows us to approximate eigenvalues that are <em>not the largest</em>.  All that is needed to make the modification is two simple facts that relate changes in a matrix to changes in the eigenvalues of that matrix.  Let’s suppose that <span class="math notranslate nohighlight">\(A\)</span> is an invertible <span class="math notranslate nohighlight">\(n\times n\)</span> matrix with eigenvalue <span class="math notranslate nohighlight">\(\lambda\)</span> and corresponding eigenvector <span class="math notranslate nohighlight">\(V\)</span>, so that <span class="math notranslate nohighlight">\(AV=\lambda V\)</span>.  If we multiply this equation by <span class="math notranslate nohighlight">\(A^{-1}\)</span>, we get <span class="math notranslate nohighlight">\(V=\lambda A^{-1}V\)</span>, which can then be divided by <span class="math notranslate nohighlight">\(\lambda\)</span> to illustrate the useful fact.</p>
<div class="math notranslate nohighlight">
\[
\begin{equation}
A^{-1}V = \frac{1}{\lambda}V
\end{equation}
\]</div>
<p>If <span class="math notranslate nohighlight">\(\lambda\)</span> is an eigenvalue of <span class="math notranslate nohighlight">\(A\)</span>, then <span class="math notranslate nohighlight">\(\lambda^{-1}\)</span> is an eigenvalue of <span class="math notranslate nohighlight">\(A^{-1}\)</span>.  Furthermore the eigenvector of <span class="math notranslate nohighlight">\(A\)</span> is also an eigenvector of <span class="math notranslate nohighlight">\(A^{-1}\)</span>.  The important point here is that if <span class="math notranslate nohighlight">\(\lambda_n\)</span> is the smallest eigenvalue of <span class="math notranslate nohighlight">\(A\)</span>, then <span class="math notranslate nohighlight">\(\lambda_n^{-1}\)</span> is the <em>largest</em> eigenvector of <span class="math notranslate nohighlight">\(A^{-1}\)</span>.  If we want to approximate the smallest eigenvalue of <span class="math notranslate nohighlight">\(A\)</span>, we can just apply the Power Method to <span class="math notranslate nohighlight">\(A^{-1}\)</span>.</p>
<p>We demonstrate the calculation for the following <span class="math notranslate nohighlight">\(3\times 3\)</span> matrix.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
A = \left[ \begin{array}{rrrr} 9 &amp; -1 &amp; -3 \\ 0 &amp; 6 &amp; 0 \\ -6 &amp; 3 &amp; 6 \end{array}\right]
\end{equation}
\end{split}\]</div>
<p>Again we choose an arbitrary <span class="math notranslate nohighlight">\(X^{(0)}\)</span>, and generate a sequence of vectors by multiplying by <span class="math notranslate nohighlight">\(A^{-1}\)</span> and scaling the result to unit length.</p>
<div class="math notranslate nohighlight">
\[
\begin{equation}
X^{(m)}=\frac{A^{-1}X^{(m-1)}}{||A^{-1}X^{(m-1)}||}
\end{equation}
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">]])</span>

<span class="n">m</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">tolerance</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">MAX_ITERATIONS</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">difference</span> <span class="o">=</span> <span class="n">X</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">9</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">A_inv</span> <span class="o">=</span> <span class="n">lag</span><span class="o">.</span><span class="n">Inverse</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="k">while</span> <span class="p">(</span><span class="n">m</span> <span class="o">&lt;</span> <span class="n">MAX_ITERATIONS</span> <span class="ow">and</span> <span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">difference</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">tolerance</span><span class="p">):</span>
    <span class="n">X_previous</span> <span class="o">=</span> <span class="n">X</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">A_inv</span><span class="nd">@X</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">/</span><span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="c1">## Compute difference in stopping condition</span>
    <span class="n">difference</span> <span class="o">=</span> <span class="n">X</span> <span class="o">-</span> <span class="n">X_previous</span>
    
    <span class="n">m</span> <span class="o">=</span> <span class="n">m</span> <span class="o">+</span> <span class="mi">1</span>
    
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Eigenvector is approximately:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Magnitude of the eigenvalue of A inverse is approximately:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">A_inv</span><span class="nd">@X</span><span class="p">),</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Magnitude of the eigenvalue of A is approximately:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">A</span><span class="nd">@X</span><span class="p">),</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Eigenvector is approximately:
[[-4.47193123e-01]
 [ 6.14168469e-05]
 [-8.94437425e-01]] 

Magnitude of the eigenvalue of A inverse is approximately:
0.3333371476391265 

Magnitude of the eigenvalue of A is approximately:
2.999931351114087 
</pre></div>
</div>
</div>
</div>
<p>The exact value of the smallest eigenvalue of <span class="math notranslate nohighlight">\(A\)</span> is 3, which again can be verified by calculation.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
AV = \left[ \begin{array}{rrrr} 9 &amp; -1 &amp; -3 \\ 0 &amp; 6 &amp; 0 \\ -6 &amp; 3 &amp; 6 \end{array}\right]
\left[ \begin{array}{r} 1 \\ 0\\ 2 \end{array}\right] =
\left[ \begin{array}{r} 3 \\ 0 \\ 6 \end{array}\right] = 3V
\end{equation}
\end{split}\]</div>
<p>In our discussion of <a class="reference internal" href="Inverse_Matrices.html"><span class="std std-doc">Inverse Matrices</span></a> we noted that the construction of an inverse matrix is quite expensive since it requires the solution of <span class="math notranslate nohighlight">\(n\)</span> systems of size <span class="math notranslate nohighlight">\(n\times n\)</span>.  An alternative to constructing <span class="math notranslate nohighlight">\(A^{-1}\)</span> and computing the  <span class="math notranslate nohighlight">\(X^{(m)}=A^{-1}X^{(m-1)}\)</span> is to solve the system <span class="math notranslate nohighlight">\(AX^{(m)}=X^{(m-1)}\)</span> to obtain <span class="math notranslate nohighlight">\(X^{(m)}\)</span>.  This means that we solve one <span class="math notranslate nohighlight">\(n\times n\)</span> system for every iteration.  This appears to require more work than the construction of <span class="math notranslate nohighlight">\(A^{-1}\)</span>, but in fact it is less since every system involves the same coefficient matrix.  We can therefore save much work by performing elimination only once and storing the result in an <span class="math notranslate nohighlight">\(LU\)</span> factorization.  With the the matrix <span class="math notranslate nohighlight">\(A\)</span> factored, each system <span class="math notranslate nohighlight">\(AX^{(m)}=X^{(m-1)}\)</span> only requires one forward substitution and one backward substitution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">scipy.linalg</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sla</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">]])</span>

<span class="n">m</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">tolerance</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">MAX_ITERATIONS</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">difference</span> <span class="o">=</span> <span class="n">X</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">9</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">LU_factorization</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">lu_factor</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="k">while</span> <span class="p">(</span><span class="n">m</span> <span class="o">&lt;</span> <span class="n">MAX_ITERATIONS</span> <span class="ow">and</span> <span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">difference</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">tolerance</span><span class="p">):</span>
    <span class="n">X_previous</span> <span class="o">=</span> <span class="n">X</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">lu_solve</span><span class="p">(</span><span class="n">LU_factorization</span><span class="p">,</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">/</span><span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">difference</span> <span class="o">=</span> <span class="n">X</span> <span class="o">-</span> <span class="n">X_previous</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">m</span> <span class="o">+</span> <span class="mi">1</span>
  
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Eigenvector is approximately:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Magnitude of the eigenvalue of A inverse is approximately:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">sla</span><span class="o">.</span><span class="n">lu_solve</span><span class="p">(</span><span class="n">LU_factorization</span><span class="p">,</span><span class="n">X</span><span class="p">)),</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Magnitude of the eigenvalue of A is approximately:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">A</span><span class="nd">@X</span><span class="p">),</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">import</span><span class="w"> </span><span class="nn">scipy.linalg</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sla</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">]])</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">m</span> <span class="o">=</span> <span class="mi">0</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;scipy&#39;
</pre></div>
</div>
</div>
</div>
</section>
<section id="shifted-inverse-power-method">
<h2>Shifted inverse power method<a class="headerlink" href="#shifted-inverse-power-method" title="Link to this heading">#</a></h2>
<p>Using a small modification to the Inverse Power Method, we can also approximate eigenvalues that are not the smallest.  For this variation of the method, we need to observe that if we “shift” the diagonal entries of a matrix by a scalar <span class="math notranslate nohighlight">\(\mu\)</span>, all of the eigenvalues of the matrix are also shifted by <span class="math notranslate nohighlight">\(\mu\)</span>.  Let <span class="math notranslate nohighlight">\(A\)</span> be an <span class="math notranslate nohighlight">\(n\times n\)</span> matrix with eigenvalue <span class="math notranslate nohighlight">\(\lambda\)</span> and corresponding eigenvector <span class="math notranslate nohighlight">\(V\)</span>, so that <span class="math notranslate nohighlight">\(AV=\lambda V\)</span>.  Then <span class="math notranslate nohighlight">\((A-\mu I)V = AV - \mu V = \lambda V - \mu V = (\lambda-\mu)V\)</span>, which means that <span class="math notranslate nohighlight">\(V\)</span> is also an eigenvector of the matrix <span class="math notranslate nohighlight">\((A-\mu I)\)</span> corresponding to the eigenvalue <span class="math notranslate nohighlight">\(\lambda -\mu\)</span>.</p>
<div class="math notranslate nohighlight">
\[
\begin{equation}
\frac{1}{\lambda_1-\mu}, \frac{1}{\lambda_2-\mu}, \frac{1}{\lambda_3-\mu}, ....,\frac{1}{\lambda_n-\mu} 
\end{equation}
\]</div>
<p>This is useful because it allows us to now use the Inverse Power Method to approximate the eigenvalue of <span class="math notranslate nohighlight">\(A\)</span> that lies closest to <span class="math notranslate nohighlight">\(\mu\)</span>.  For example, if <span class="math notranslate nohighlight">\(\mu\)</span> is closest to <span class="math notranslate nohighlight">\(\lambda_2\)</span>, then <span class="math notranslate nohighlight">\(|\lambda_2-\mu| &lt; |\lambda_i -\mu|\)</span> for all other <span class="math notranslate nohighlight">\(i\neq 2\)</span>, which means that <span class="math notranslate nohighlight">\((\lambda_2-\mu)\)</span> can be approximated by applying the Inverse Power Method to <span class="math notranslate nohighlight">\((A-\mu I)\)</span>.</p>
<p>We demonstrate the computation of the middle eigenvalue of the matrix from the previous example.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
A = \left[ \begin{array}{rrrr} 9 &amp; -1 &amp; -3 \\ 0 &amp; 6 &amp; 0 \\ -6 &amp; 3 &amp; 6 \end{array}\right]
\end{equation}
\end{split}\]</div>
<p>By using the Inverse Power Method we determined that the smallest eigenvalue of <span class="math notranslate nohighlight">\(A\)</span> is 3.  Applying the Power Method directly will show that the largest eigenvalue of <span class="math notranslate nohighlight">\(A\)</span> is 12.  Since the third eigenvalue must lie somewhere in between these extremes, we choose <span class="math notranslate nohighlight">\(\mu\)</span> to be exactly in the middle at <span class="math notranslate nohighlight">\(7.5\)</span>.  Note that once we have a good approximation to the eigenvector with <span class="math notranslate nohighlight">\(X^{(m)}\)</span>, we can approximate the eigenvalue of <span class="math notranslate nohighlight">\(A\)</span> with <span class="math notranslate nohighlight">\(||AX^{(m)}||\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">]])</span>

<span class="n">m</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">tolerance</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">MAX_ITERATIONS</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">difference</span> <span class="o">=</span> <span class="n">X</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">9</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">I</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">mu</span> <span class="o">=</span> <span class="mf">7.5</span>
<span class="n">Shifted_A</span> <span class="o">=</span> <span class="n">A</span><span class="o">-</span><span class="n">mu</span><span class="o">*</span><span class="n">I</span>
<span class="n">LU_factorization</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">lu_factor</span><span class="p">(</span><span class="n">Shifted_A</span><span class="p">)</span>

<span class="k">while</span> <span class="p">(</span><span class="n">m</span> <span class="o">&lt;</span> <span class="n">MAX_ITERATIONS</span> <span class="ow">and</span> <span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">difference</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">tolerance</span><span class="p">):</span>
    <span class="n">X_previous</span> <span class="o">=</span> <span class="n">X</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">lu_solve</span><span class="p">(</span><span class="n">LU_factorization</span><span class="p">,</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">/</span><span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="c1">## Compute difference in stopping condition</span>
    <span class="n">difference</span> <span class="o">=</span> <span class="n">X</span> <span class="o">-</span> <span class="n">X_previous</span>
    
    <span class="n">m</span> <span class="o">=</span> <span class="n">m</span> <span class="o">+</span> <span class="mi">1</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Eigenvector is approximately:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Eigenvalue of A is approximately:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lag</span><span class="o">.</span><span class="n">Magnitude</span><span class="p">(</span><span class="n">A</span><span class="nd">@X</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Eigenvector is approximately:
[[0.44232587]
 [0.88465174]
 [0.14744196]] 

Eigenvalue of A is approximately:
6.0
</pre></div>
</div>
</div>
</div>
</section>
<section id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h2>
<p><strong>Exercise 1:</strong> Let <span class="math notranslate nohighlight">\(A\)</span> be the matrix from the Inverse Power Method example.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
A = \left[ \begin{array}{rrr} 9 &amp; -1 &amp; -3 \\ 0 &amp; 6 &amp; 0 \\ -6 &amp; 3 &amp; 6 \end{array}\right]
\end{equation}
\end{split}\]</div>
<p>(<span class="math notranslate nohighlight">\(a\)</span>) Use the Power Method to approximate the largest eigenvalue <span class="math notranslate nohighlight">\(\lambda_1\)</span>.  Verify that the exact value of <span class="math notranslate nohighlight">\(\lambda_1\)</span> is 12.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Code solution here.</span>
</pre></div>
</div>
</div>
</div>
<p>(<span class="math notranslate nohighlight">\(b\)</span>) Apply the Inverse Power Method with a shift of <span class="math notranslate nohighlight">\(\mu = 10\)</span>.  Explain why the results differ from those in the example.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Code solution here.</span>
</pre></div>
</div>
</div>
</div>
<p>(<span class="math notranslate nohighlight">\(c\)</span>) Apply the Inverse Power Method with a shift of <span class="math notranslate nohighlight">\(\mu = 7.5\)</span> and the initial vector given below.  Explain why the sequence of vectors approach the eigenvector corresponding to <span class="math notranslate nohighlight">\(\lambda_1\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
X^{(0)} = \left[ \begin{array}{r} 1 \\ 0  \\ 0 \end{array}\right]
\end{equation}
\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Code solution here.</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Exercise 2:</strong>* Let <span class="math notranslate nohighlight">\(B\)</span> be the following matrix.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
B = \left[ \begin{array}{rrrr} -2 &amp; -18 &amp; 6 \\ -11 &amp; 3 &amp; 11 \\ -27 &amp; 15 &amp; 31 \end{array}\right]
\end{equation}
\end{split}\]</div>
<p>(<span class="math notranslate nohighlight">\(a\)</span>) Apply the Power Method and Inverse Power Method with shifts to approximate all eigenvalues of the matrix <span class="math notranslate nohighlight">\(B\)</span>. (<em>Note that one of the eigenvalues of this matrix is negative.</em>)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Code solution here.</span>
</pre></div>
</div>
</div>
</div>
<p>(<span class="math notranslate nohighlight">\(b\)</span>) Check your results using the <span class="math notranslate nohighlight">\(\texttt{eig}\)</span> function in SciPy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Code solution here.</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Burden, Richard L. et al. <em>Numerical Analysis</em>. 10th ed., Cengage Learning, 2014</p></li>
<li><p>Golub, Gene H. and Charles F. Van Loan. <em>Matrix Computations</em>., The Johns Hopkins University Press, 1989</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "executablebooks/jupyter-book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Diagonalization.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Diagonalization</p>
      </div>
    </a>
    <a class="right-next"
       href="Applications_EV.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Applications of Eigenvalues and Eigenvectors</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#power-method">Power method</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inverse-power-method">Inverse power method</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shifted-inverse-power-method">Shifted inverse power method</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Aditya Chaturvedi
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>